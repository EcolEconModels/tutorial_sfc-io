---
title: "Minimal SFC-IO Tutorial (Answer Version)"
format:
  html:
    toc: true
    number-sections: true
    embed-resources: true
  revealjs:
    slide-number: true
    incremental: false
    embed-resources: true
execute:
  echo: true
  warning: false
  message: false
---

This file is the canonical answer tutorial source. The question variant is generated from exercise metadata tags annotations.

## Shared Setup

Load minimal packages and global options only.

Check that required packages are installed.
Stop early with a clear error if anything is missing.
This keeps the tutorial run deterministic and minimal.
```{r setup_packages}
required_packages <- c("jsonlite", "ggplot2")
missing_packages <- required_packages[!vapply(required_packages, requireNamespace, logical(1), quietly = TRUE)]
if (length(missing_packages) > 0) {
  stop("Missing package(s): ", paste(missing_packages, collapse = ", "), call. = FALSE)
}
```

## Step 1: SIM Closed Model

### Objective

Build SIM-lag first, then add SIM-current, then compare both against the analytic fixed point.

### Equations

- `Y_t = C_t + G`
- `T_t = theta * Y_t`
- `YD_t = Y_t - T_t`
- `C_t(lag) = alpha1 * YD_{t-1} + alpha2 * H_{t-1}`
- `C_t(current) = alpha1 * YD_t + alpha2 * H_{t-1}`
- `H_t = H_{t-1} + YD_t - C_t`
- `Y* = G / theta`

Steady-state derivation (SIM):
- At steady state, stocks are constant: `H_t = H_{t-1}` so `0 = YD - C`, hence `C = YD = (1-theta)Y`.
- Goods market: `Y = C + G = (1-theta)Y + G`.
- Rearranging: `theta * Y = G`, so `Y* = G / theta`.
- From behavior at steady state: `C = alpha1*(1-theta)Y + alpha2*H` and `C = (1-theta)Y`.
- Therefore: `H* = ((1-alpha1)*(1-theta)/alpha2) * Y* = ((1-alpha1)*(1-theta)/alpha2) * (G/theta)`.
- This fixed-point GDP is independent of `alpha1` and `alpha2`; those affect only transition dynamics.

Define fixed point and lag simulation.

Define the SIM-lag dynamics as a simple time loop.
Consumption depends on lagged disposable income and past wealth.
The function returns a tidy time-series for plotting and comparisons.
```{r step1_functions_sim_core}
simulate_sim_lag <- function(T = 20, G = 100, theta = 0.2, alpha1 = 0.6, alpha2 = 0.2, Y0 = 80, H0 = 300) {
  out <- data.frame(t = seq_len(T), Y = NA_real_, T_tax = NA_real_, YD = NA_real_, C = NA_real_, H = NA_real_)
  YD_prev <- (1 - theta) * Y0
  H_prev <- H0
  for (tt in seq_len(T)) {
    C_t <- alpha1 * YD_prev + alpha2 * H_prev
    Y_t <- C_t + G
    T_t <- theta * Y_t
    YD_t <- Y_t - T_t
    H_t <- H_prev + YD_t - C_t
    out[tt, c("Y", "T_tax", "YD", "C", "H")] <- c(Y_t, T_t, YD_t, C_t, H_t)
    YD_prev <- YD_t
    H_prev <- H_t
  }
  out
}
```

Run SIM-lag from below steady state.

Set baseline SIM parameters and compute the fixed point Y*.
Choose an initial GDP below Y* and derive a consistent H0.
Run the lag model to generate the convergence path.
```{r step1_run_lag_below}
T_h <- 20
G <- 100
theta <- 0.2
alpha1 <- 0.6
alpha2 <- 0.2
Y_star <- G / theta
Y0_low <- 0.7 * Y_star
H0_low <- (Y0_low * (1 - alpha1 * (1 - theta)) - G) / alpha2
lag_low <- simulate_sim_lag(T = T_h, G = G, theta = theta, alpha1 = alpha1, alpha2 = alpha2, Y0 = Y0_low, H0 = H0_low)
```

Plot lag path from below.

Plot the GDP path from the lag model.
Overlay the analytic fixed point as a horizontal reference.
This visualizes convergence from below.
```{r step1_plot_lag_below, fig.height=4, fig.width=7}
yr <- range(c(lag_low$Y, Y_star), na.rm = TRUE)
pad <- 0.05 * diff(yr); if (!is.finite(pad) || pad <= 0) pad <- 1
plot(lag_low$t, lag_low$Y, type = "l", lwd = 2, col = "steelblue",
     ylim = c(yr[1] - pad, yr[2] + pad),
     xlab = "t", ylab = "GDP", main = "Step 1A: SIM-lag from below fixed point")
abline(h = Y_star, lty = 2)
```

Core play: start above steady state and compare.

Change the initial GDP to start above the fixed point.
Compute the consistent H0 and rerun the lag model.
Plot below/above paths together to compare convergence.
```{r step1_play_core_lag_above}
Y0_high_play <- 1.1 * Y_star  # TODO [core:step1_high_start] Start GDP above fixed point and compare convergence Hint: Try 1.1, 1.3, then 1.6 times Y*
H0_high_play <- (Y0_high_play * (1 - alpha1 * (1 - theta)) - G) / alpha2
lag_high_play <- simulate_sim_lag(T = T_h, G = G, theta = theta, alpha1 = alpha1, alpha2 = alpha2, Y0 = Y0_high_play, H0 = H0_high_play)

yr <- range(c(lag_low$Y, lag_high_play$Y, Y_star), na.rm = TRUE)
pad <- 0.05 * diff(yr); if (!is.finite(pad) || pad <= 0) pad <- 1
plot(lag_low$t, lag_low$Y, type = "l", lwd = 2, col = "steelblue",
     ylim = c(yr[1] - pad, yr[2] + pad),
     xlab = "t", ylab = "GDP", main = "Step 1B: SIM-lag from below and above")
lines(lag_high_play$t, lag_high_play$Y, lwd = 2, col = "firebrick")
abline(h = Y_star, lty = 2)
legend("right", legend = c("below start", "above start", "Y*"),
       col = c("steelblue", "firebrick", "black"), lty = c(1, 1, 2), bty = "n")
```

Now add SIM-current fixed-point simulation.

Define SIM-current with within-period fixed-point iteration.
Each period solves Y from current disposable income and wealth.
This makes income–consumption contemporaneous instead of lagged.
```{r step1_functions_sim_current}
simulate_sim_current_fp <- function(T = 20, G = 100, theta = 0.2, alpha1 = 0.6, alpha2 = 0.2,
                                    Y0 = 80, H0 = 300, fp_tol = 1e-10, fp_max = 200) {
  out <- data.frame(t = seq_len(T), Y = NA_real_, T_tax = NA_real_, YD = NA_real_, C = NA_real_, H = NA_real_)
  H_prev <- H0
  Y_prev <- Y0
  for (tt in seq_len(T)) {
    Y_guess <- Y_prev
    n_iter <- 0L
    repeat {
      n_iter <- n_iter + 1L
      Y_new <- G + alpha1 * (1 - theta) * Y_guess + alpha2 * H_prev
      if (abs(Y_new - Y_guess) < fp_tol || n_iter >= fp_max) break
      Y_guess <- Y_new
    }
    Y_t <- Y_new
    T_t <- theta * Y_t
    YD_t <- Y_t - T_t
    C_t <- Y_t - G
    H_t <- H_prev + YD_t - C_t
    out[tt, c("Y", "T_tax", "YD", "C", "H")] <- c(Y_t, T_t, YD_t, C_t, H_t)
    H_prev <- H_t
    Y_prev <- Y_t
  }
  out
}
```

Compare lag and current dynamics.

Run SIM-current from below and above the fixed point.
Plot lag and current dynamics together for comparison.
This shows how timing assumptions affect transients.
```{r step1_run_compare_lag_current}
cur_low <- simulate_sim_current_fp(T = T_h, G = G, theta = theta, alpha1 = alpha1, alpha2 = alpha2, Y0 = Y0_low, H0 = H0_low)
cur_high <- simulate_sim_current_fp(T = T_h, G = G, theta = theta, alpha1 = alpha1, alpha2 = alpha2, Y0 = Y0_high_play, H0 = H0_high_play)

yr <- range(c(lag_low$Y, lag_high_play$Y, cur_low$Y, cur_high$Y, Y_star), na.rm = TRUE)
pad <- 0.05 * diff(yr); if (!is.finite(pad) || pad <= 0) pad <- 1
plot(lag_low$t, lag_low$Y, type = "l", lwd = 2, col = "steelblue",
     ylim = c(yr[1] - pad, yr[2] + pad),
     xlab = "t", ylab = "GDP", main = "Step 1C: SIM-lag vs SIM-current")
lines(lag_high_play$t, lag_high_play$Y, lwd = 2, col = "firebrick")
lines(cur_low$t, cur_low$Y, lwd = 2, col = "darkgreen")
lines(cur_high$t, cur_high$Y, lwd = 2, col = "purple4")
abline(h = Y_star, lty = 2)
legend("right", legend = c("Lag below", "Lag above", "Current below", "Current above", "Y*"),
       col = c("steelblue", "firebrick", "darkgreen", "purple4", "black"),
       lty = c(1, 1, 1, 1, 2), bty = "n")
```

Optional play: adjust wealth propensity in both variants.

Vary the propensity to consume out of wealth (alpha2).
Rerun both lag and current versions with the new alpha2.
Plot the impact on speed of convergence.
```{r step1_play_optional_alpha2}
alpha2_play <- 0.1  # TODO [optional:step1_alpha2] Change alpha2 and compare speed of convergence Hint: Lower alpha2 usually slows wealth-driven demand

lag_opt <- simulate_sim_lag(T = T_h, G = G, theta = theta, alpha1 = alpha1, alpha2 = alpha2_play, Y0 = Y0_low, H0 = H0_low)
cur_opt <- simulate_sim_current_fp(T = T_h, G = G, theta = theta, alpha1 = alpha1, alpha2 = alpha2_play, Y0 = Y0_low, H0 = H0_low)

plot(lag_opt$t, lag_opt$Y, type = "l", lwd = 2, col = "steelblue",
     xlab = "t", ylab = "GDP", main = "Step 1 Optional: effect of alpha2")
lines(cur_opt$t, cur_opt$Y, lwd = 2, col = "darkgreen")
legend("right", legend = c("Lag", "Current"), col = c("steelblue", "darkgreen"), lty = 1, bty = "n")
```

### Interpretation

Both dynamic versions converge to the same fixed point, but with different transient paths.

## Step 2: SIM + IOT Baseline Fit

### Objective

Integrate SIM stocks-flows with IOT production, fit to base-year data, and simulate a 20-year no-transition baseline.

### Equations

- `x_t = L f_t`
- `Y_t = sum_i(v_i x_i,t)`
- `T_t = tau_y * Y_t`
- `C_t = c_y * YD_t + c_v * V_{t-1}`
- `V_t = V_{t-1} + YD_t - C_t`
- `DEF_t = G_t - T_t`, `B_t = B_{t-1} + DEF_t`

### IO Setup for Step 2

Load and calibrate IO objects here so Step 2 (core) is self-contained.
Step 4 later reuses the same functions for advanced exogenous closure experiments.

Declare shared IO data configuration for Steps 2 and 3 (and later Step 4 advanced).

Configure the IO dataset once for the core integrated model blocks.
Set country/year/scope/table type here so all later runs are consistent.
This same config is reused in Step 3 and in optional Step 4 advanced experiments.
```{r step2_run_config}
make_core_config <- function() {
  list(
    country = Sys.getenv("SFC_IO_COUNTRY", "AT"),
    year = Sys.getenv("SFC_IO_YEAR", "2020"),
    scope = Sys.getenv("SFC_IO_SCOPE", "TOTAL"),
    table_type = Sys.getenv("SFC_IO_TABLE_TYPE", "product_by_product"),
    freq = "A",
    iot_unit = "MIO_EUR",
    wealth_unit = "MIO_EUR",
    wealth_co_nco = "NCO",
    wealth_na_item = "BF90",
    wealth_finpos = "LIAB",
    cache_dir = "data"
  )
}
core_config <- make_core_config()
```

Define IO download/parsing helpers used by the core integrated model.

This block defines the IO data plumbing used in the integrated model.
Algorithm: build a deterministic cache key from query parameters, then fetch from cache or Eurostat.
Algorithm: decode JSON-stat dimension indices into ordered category tables for rows/columns.
Algorithm: reconstruct dense matrices from sparse JSON-stat value maps.
These helpers isolate API/parsing complexity from the economics logic used later.
```{r step2_functions_iot_helpers}

ensure_cache_dir <- function(cache_dir = "data") {
  if (!dir.exists(cache_dir)) dir.create(cache_dir, recursive = TRUE)
  cache_dir
}

sanitize_for_filename <- function(x) gsub("[^A-Za-z0-9_\\-]", "_", x)

cache_file_for_query <- function(dataset_id, params, cache_dir) {
  key_parts <- character(0)
  for (nm in names(params)) {
    vv <- params[[nm]]
    for (v in vv) key_parts <- c(key_parts, paste0(nm, "-", as.character(v)))
  }
  file.path(cache_dir, paste0(dataset_id, "__", sanitize_for_filename(paste(key_parts, collapse = "__")), ".json"))
}

query_cache_paths <- function(dataset_id, params, cache_dir) {
  json_file <- cache_file_for_query(dataset_id, params, cache_dir)
  rds_file <- sub("\\.json$", ".rds", json_file)
  list(json = json_file, rds = rds_file)
}

build_query_parts <- function(params) {
  q <- character(0)
  for (nm in names(params)) {
    vv <- params[[nm]]
    for (v in vv) q <- c(q, paste0(nm, "=", utils::URLencode(as.character(v), reserved = TRUE)))
  }
  q
}

fetch_eurostat_json <- function(dataset_id, params, cache_dir = "data") {
  cache_dir <- ensure_cache_dir(cache_dir)
  cache_file <- cache_file_for_query(dataset_id, params, cache_dir)
  if (file.exists(cache_file)) return(jsonlite::read_json(cache_file, simplifyVector = FALSE))
  base <- "https://ec.europa.eu/eurostat/api/dissemination/statistics/1.0/data"
  url <- paste0(base, "/", dataset_id, "?", paste(build_query_parts(params), collapse = "&"))
  utils::download.file(url, destfile = cache_file, mode = "wb", quiet = TRUE)
  jsonlite::read_json(cache_file, simplifyVector = FALSE)
}

ordered_categories <- function(dim_obj) {
  raw_idx <- unlist(dim_obj[["category"]][["index"]])
  ord <- order(as.integer(raw_idx))
  codes <- names(raw_idx)[ord]
  lbl_all <- dim_obj[["category"]][["label"]]
  labels <- unlist(lbl_all[codes])
  labels[is.na(labels)] <- codes[is.na(labels)]
  data.frame(code = codes, label = labels, stringsAsFactors = FALSE)
}

decode_jsonstat_index <- function(flat0, sizes) {
  k <- length(sizes)
  pos <- integer(k)
  rem <- as.integer(flat0)
  for (i in seq_len(k)) {
    stride <- if (i == k) 1L else as.integer(prod(sizes[(i + 1):k]))
    pos[i] <- rem %/% stride
    rem <- rem %% stride
  }
  pos
}

extract_matrix_from_json <- function(js, row_dim, col_dim) {
  ids <- unlist(js[["id"]])
  sizes <- as.integer(unlist(js[["size"]]))
  row_i <- match(row_dim, ids)
  col_i <- match(col_dim, ids)
  row_cat <- ordered_categories(js[["dimension"]][[row_dim]])
  col_cat <- ordered_categories(js[["dimension"]][[col_dim]])
  vals <- unlist(js[["value"]])
  M <- matrix(NA_real_, nrow = nrow(row_cat), ncol = nrow(col_cat))
  flat_idx <- as.integer(names(vals))
  for (j in seq_along(flat_idx)) {
    pos <- decode_jsonstat_index(flat_idx[j], sizes)
    M[pos[row_i] + 1L, pos[col_i] + 1L] <- as.numeric(vals[[j]])
  }
  list(M = M, row_cat = row_cat, col_cat = col_cat)
}

iot_schema <- function(table_type) {
  if (identical(table_type, "industry_by_industry")) {
    list(dataset_id = "naio_10_cp1750", row_dim = "ind_ava", col_dim = "ind_use")
  } else {
    list(dataset_id = "naio_10_cp1700", row_dim = "prd_ava", col_dim = "prd_use")
  }
}

sum_matching_cols <- function(M, col_codes, col_labels, patterns) {
  p <- paste(patterns, collapse = '|')
  hit <- grepl(p, col_codes, ignore.case = TRUE) | grepl(p, col_labels, ignore.case = TRUE)
  if (!any(hit)) return(rep(0, nrow(M)))
  rowSums(M[, hit, drop = FALSE], na.rm = TRUE)
}

find_energy_indices <- function(sector_codes) {
  idx_brown <- grep("(^|_)C19", sector_codes)[1]
  idx_green <- grep("(^|_)D35|(^|_)D", sector_codes)[1]
  if (is.na(idx_brown) || is.na(idx_green)) stop("Energy sectors not found for this IOT configuration.", call. = FALSE)
  list(idx_green = idx_green, idx_brown = idx_brown)
}

extract_values_by_dim <- function(js, dim_name) {
  ids <- unlist(js[['id']])
  sizes <- as.integer(unlist(js[['size']]))
  dim_i <- match(dim_name, ids)
  cat_tbl <- ordered_categories(js[['dimension']][[dim_name]])
  vals <- unlist(js[['value']])
  out <- setNames(rep(NA_real_, nrow(cat_tbl)), cat_tbl$code)
  flat_idx <- as.integer(names(vals))
  for (j in seq_along(flat_idx)) {
    pos <- decode_jsonstat_index(flat_idx[j], sizes)
    out[cat_tbl$code[pos[dim_i] + 1L]] <- as.numeric(vals[[j]])
  }
  out
}
```

Define compact IOT loader for the core SIM+IOT steps.

This block builds the core IO objects used by Steps 2, 3, and 4.
Pseudo-code: identify sectors, compute Z/A/L, and extract C/G/I/EX vectors from IO uses.
Pseudo-code: compute import leakage m_i, value-added coefficients, and beta demand shares.
This keeps core IO calibration separate from advanced closure experiments introduced in Step 5.
```{r step2_functions_iot_sim}
download_or_load_iot <- function(cfg) {
  schema <- iot_schema(cfg$table_type)
  params <- list(freq = cfg$freq, unit = cfg$iot_unit, stk_flow = cfg$scope, geo = cfg$country, time = as.character(cfg$year))
  cache_paths <- query_cache_paths(paste0(schema$dataset_id, "_iot"), params, cfg$cache_dir)
  if (file.exists(cache_paths$rds)) return(readRDS(cache_paths$rds))
  js <- fetch_eurostat_json(schema$dataset_id, params, cache_dir = cfg$cache_dir)
  mat <- extract_matrix_from_json(js, schema$row_dim, schema$col_dim)

  row_codes <- mat$row_cat$code
  row_labels <- mat$row_cat$label
  col_codes <- mat$col_cat$code
  col_labels <- mat$col_cat$label

  tu_col <- match('TU', col_codes)
  if (is.na(tu_col)) tu_col <- match('TOTAL', col_codes)

  x_by_row <- mat$M[, tu_col]
  names(x_by_row) <- row_codes
  exclude <- c('TOTAL', 'TU', 'TFU', 'TS_BP', 'IMP', 'B1G', 'P1', 'P2_ADJ', 'P7', 'P7_B0', 'P7_D0', 'P7_U2', 'P7_U3')
  sector_codes <- setdiff(intersect(row_codes, col_codes), exclude)
  sector_codes <- intersect(sector_codes, names(x_by_row)[is.finite(x_by_row) & x_by_row > 1e-9])

  r_idx <- match(sector_codes, row_codes)
  c_idx <- match(sector_codes, col_codes)
  Z <- mat$M[r_idx, c_idx, drop = FALSE]
  x0 <- as.numeric(x_by_row[sector_codes])
  names(x0) <- sector_codes

  A0 <- sweep(Z, 2, pmax(x0, 1e-9), '/')
  A0[!is.finite(A0)] <- 0
  L0 <- solve(diag(length(sector_codes)) - A0 + diag(1e-8, length(sector_codes)))

  Msel <- mat$M[r_idx, , drop = FALSE]
  C_i0 <- sum_matching_cols(Msel, col_codes, col_labels, c('^P3_S14$', 'households'))
  C_i0 <- C_i0 + sum_matching_cols(Msel, col_codes, col_labels, c('^P3_S15$', 'NPISH'))
  G_i0 <- sum_matching_cols(Msel, col_codes, col_labels, c('^P3_S13$', 'government'))
  I_i0 <- sum_matching_cols(Msel, col_codes, col_labels, c('^P51G$', '^P52$', '^P53$', '^P5$', 'gross capital'))
  EX_i0 <- sum_matching_cols(Msel, col_codes, col_labels, c('^P6$', '^P6_', 'exports'))

  imp_row <- which(row_codes %in% c('P7', 'IMP'))
  imports_i <- as.numeric(mat$M[imp_row[1], c_idx, drop = TRUE])
  imports_i[!is.finite(imports_i)] <- 0

  m_i <- pmin(pmax(imports_i / pmax(x0, 1e-9), 0), 0.95)
  va_row <- which(row_codes == 'B1G')
  va_coeff <- as.numeric(mat$M[va_row[1], c_idx, drop = TRUE]) / pmax(x0, 1e-9)
  va_coeff[!is.finite(va_coeff)] <- 0
  va_coeff <- pmax(va_coeff, 0)

  beta_C <- C_i0 / sum(C_i0)
  beta_G <- G_i0 / sum(G_i0)
  beta_C[!is.finite(beta_C)] <- 0
  beta_G[!is.finite(beta_G)] <- 0
  if (sum(beta_C) > 0) beta_C <- beta_C / sum(beta_C)
  if (sum(beta_G) > 0) beta_G <- beta_G / sum(beta_G)

  out <- list(
    base_year = as.integer(cfg$year),
    country = cfg$country,
    scope = cfg$scope,
    table_type = cfg$table_type,
    dataset_id = schema$dataset_id,
    n = length(sector_codes),
    sector_codes = sector_codes,
    sector_labels = row_labels[r_idx],
    Z0 = Z,
    A0 = A0,
    L0 = L0,
    x0 = x0,
    C_i0 = C_i0,
    G_i0 = G_i0,
    I_i0 = I_i0,
    EX_i0 = EX_i0,
    F0 = C_i0 + G_i0 + I_i0 + EX_i0,
    m_i = m_i,
    va_coeff = va_coeff,
    Y0 = sum(va_coeff * x0),
    G0 = sum(G_i0),
    beta_C = beta_C,
    beta_G = beta_G
  )
  saveRDS(out, cache_paths$rds)
  out
}

```

Load IOT for requested configuration.

Load the IO table for the configured country/year.
Print a quick summary of the dataset used.
This confirms what will feed into the transition run.
Define Step 2 helper functions.

This block defines the endogenous SIM+IO engine for the core tutorial path.
Pseudo-code: load wealth stocks, calibrate fiscal/demand parameters, then initialize macro and sector states.
Each year: update G, shift brown/green demand shares from endogenous output signals.
Solve C via reduced-form fixed point, map demand through L to output, then update V and B stocks.
Store macro and transition indicators for interpretation and scenario comparison.
```{r step2_functions_sim_iot}
load_wealth_init <- function(cfg) {
  params <- list(
    freq = cfg$freq,
    unit = cfg$wealth_unit,
    co_nco = cfg$wealth_co_nco,
    sector = c("S13", "S14"),
    finpos = cfg$wealth_finpos,
    na_item = cfg$wealth_na_item,
    geo = cfg$country,
    time = as.character(cfg$year)
  )
  cache_paths <- query_cache_paths("nasa_10_f_bs_wealth", params, cfg$cache_dir)
  if (file.exists(cache_paths$rds)) return(readRDS(cache_paths$rds))
  js <- fetch_eurostat_json("nasa_10_f_bs", params, cache_dir = cfg$cache_dir)
  vals <- extract_values_by_dim(js, "sector")
  out <- list(V0 = as.numeric(vals[["S14"]]), B0 = max(-as.numeric(vals[["S13"]]), 0))
  saveRDS(out, cache_paths$rds)
  out
}

calibrate_sim_iot <- function(iot, wealth_init, tau_y = NULL) {
  tau_guess <- if (is.null(tau_y)) min(max(iot$G0 / pmax(iot$Y0, 1), 0.1), 0.5) else tau_y
  list(
    base_year = iot$base_year,
    n = iot$n,
    sector_codes = iot$sector_codes,
    sector_labels = iot$sector_labels,
    L = iot$L0,
    va_coeff = iot$va_coeff,
    beta_C = iot$beta_C,
    beta_G = iot$beta_G,
    I_i0 = iot$I_i0,
    G0 = iot$G0,
    tau_y = tau_guess,
    V0 = wealth_init$V0,
    B0 = wealth_init$B0,
    idx = find_energy_indices(iot$sector_codes)
  )
}

simulate_sim_iot_endogenous <- function(calib,
                                        T = 20,
                                        c_y = 0.82,
                                        c_v = 0.03,
                                        g_G = 0.01,
                                        transition_speed = 0.0015,
                                        transition_signal_weight = 1) {
  years <- calib$base_year + seq_len(T) - 1
  out <- data.frame(
    year = years,
    GDP = NA_real_, TAX = NA_real_, YD = NA_real_, C = NA_real_, G = NA_real_,
    V = NA_real_, DEF = NA_real_, B = NA_real_, betaC_brown = NA_real_, betaC_green = NA_real_
  )

  V_prev <- calib$V0
  B_prev <- calib$B0
  G_prev <- calib$G0
  x_prev <- as.numeric(calib$L %*% (calib$beta_C * sum(calib$I_i0) + calib$beta_G * calib$G0 + calib$I_i0))
  beta_C <- calib$beta_C
  beta_G <- calib$beta_G

  for (tt in seq_len(T)) {
    G_t <- if (tt == 1) calib$G0 else G_prev * (1 + g_G)

    if (is.finite(calib$idx$idx_green) && is.finite(calib$idx$idx_brown)) {
      signal <- (x_prev[calib$idx$idx_green] - x_prev[calib$idx$idx_brown]) / pmax(sum(abs(x_prev)), 1)
      shift <- max(0, transition_speed * (1 + transition_signal_weight * signal))
      shift <- min(shift, max(beta_C[calib$idx$idx_brown] - 1e-8, 0))
      beta_C[calib$idx$idx_brown] <- beta_C[calib$idx$idx_brown] - shift
      beta_C[calib$idx$idx_green] <- beta_C[calib$idx$idx_green] + shift
    }

    k <- as.numeric(t(calib$va_coeff) %*% (calib$L %*% beta_C))
    b <- as.numeric(t(calib$va_coeff) %*% (calib$L %*% (beta_G * G_t + calib$I_i0)))
    den <- 1 - c_y * (1 - calib$tau_y) * k
    C_t <- max((c_y * (1 - calib$tau_y) * b + c_v * V_prev) / den, 0)

    fd_t <- beta_C * C_t + beta_G * G_t + calib$I_i0
    x_t <- pmax(as.numeric(calib$L %*% fd_t), 0)
    Y_t <- sum(calib$va_coeff * x_t)
    TAX_t <- calib$tau_y * Y_t
    YD_t <- Y_t - TAX_t

    V_t <- V_prev + YD_t - C_t
    DEF_t <- G_t - TAX_t
    B_t <- B_prev + DEF_t

    out[tt, c("GDP", "TAX", "YD", "C", "G", "V", "DEF", "B", "betaC_brown", "betaC_green")] <- c(
      Y_t, TAX_t, YD_t, C_t, G_t, V_t, DEF_t, B_t,
      if (is.finite(calib$idx$idx_brown)) beta_C[calib$idx$idx_brown] else NA_real_,
      if (is.finite(calib$idx$idx_green)) beta_C[calib$idx$idx_green] else NA_real_
    )

    x_prev <- x_t
    V_prev <- V_t
    B_prev <- B_t
    G_prev <- G_t
  }

  out
}
```

Calibrate SIM+IOT from Step 2 data.

Load IO and wealth data for the core configuration.
Construct the SIM+IOT calibration once and keep core data in memory.
Reuse these objects in Steps 3, 4, and 5 to avoid repeated downloads/parsing.
```{r step2_run_calibrate}
core_config <- make_core_config()
if (!exists("core_iot", inherits = FALSE) || !identical(core_iot$country, core_config$country) || !identical(core_iot$scope, core_config$scope) || !identical(core_iot$table_type, core_config$table_type) || !identical(as.integer(core_iot$base_year), as.integer(core_config$year))) {
  core_iot <- download_or_load_iot(core_config)
}
if (!exists("core_wealth", inherits = FALSE) || !is.list(core_wealth) || !all(c("V0", "B0") %in% names(core_wealth))) {
  core_wealth <- load_wealth_init(core_config)
}
calib3 <- calibrate_sim_iot(core_iot, core_wealth)
```

Run 20-year baseline simulation (no endogenous transition).

Run the fitted SIM+IOT baseline with transition speed fixed at zero.
This gives the fitted no-transition reference path for Step 3.
Use it as the comparison benchmark.
```{r step2_run_baseline}
step2_baseline <- simulate_sim_iot_endogenous(calib3, T = 20, transition_speed = 0)
```

Core play: fiscal stance in baseline (no transition).

Change government spending growth while keeping transition switched off.
Rerun the baseline and compare output with government debt dynamics.
This isolates fiscal-policy effects before transition dynamics are introduced.
```{r step2_play_core_fiscal}
g_G_play <- 0.00  # TODO [core:step2_gG] Change baseline government spending growth and compare GDP/debt paths Hint: Try 0.00, 0.01, 0.03
step2_core_play <- simulate_sim_iot_endogenous(calib3, T = 20, g_G = g_G_play, transition_speed = 0)
```

Plot Step 2 core comparison.

Plot GDP for baseline and fiscal-play runs in baseline mode.
Add government debt to see the macro-financial trade-off.
This is the key Step 2 policy comparison figure.
```{r step2_plot_core, fig.height=4, fig.width=7}
par(mfrow = c(1, 2))
plot(step2_baseline$year, step2_baseline$GDP, type = "l", lwd = 2, col = "steelblue",
     xlab = "year", ylab = "GDP", main = "Step 2 Core: GDP")
lines(step2_core_play$year, step2_core_play$GDP, lwd = 2, col = "firebrick")
legend("topleft", legend = c("baseline", paste0("g_G=", g_G_play)), col = c("steelblue", "firebrick"), lty = 1, bty = "n")
plot(step2_baseline$year, step2_baseline$B, type = "l", lwd = 2, col = "steelblue",
     xlab = "year", ylab = "Gov debt B", main = "Step 2 Core: Debt")
lines(step2_core_play$year, step2_core_play$B, lwd = 2, col = "firebrick")
par(mfrow = c(1, 1))
```

Optional play: baseline wealth-consumption behavior.

Change consumption out of wealth with transition still off.
Rerun the baseline and inspect wealth-stock dynamics.
This shows behavior-driven demand effects before adding transition pressure.
```{r step2_play_optional_cv}
c_v_baseline_play <- 0.01  # TODO [optional:step2_cv] Change baseline c_v and inspect wealth and GDP without transition Hint: Keep transition_speed = 0
step2_opt <- simulate_sim_iot_endogenous(calib3, T = 20, c_v = c_v_baseline_play, transition_speed = 0)

ggplot2::ggplot(step2_opt, ggplot2::aes(year, V)) +
  ggplot2::geom_line(linewidth = 1, color = "darkgreen") +
  ggplot2::labs(title = "Step 2 Optional: household wealth path (no transition)", y = "V") +
  ggplot2::theme_minimal()
```

### Interpretation

Step 2 fits the integrated SIM+IOT structure and produces a 20-year baseline path without activating transition pressure.

## Step 3: Endogenous Transition

### Objective

Start from the fitted Step 2 model and activate endogenous energy reallocation to study dynamic transition effects.

### Equations

- `shift_t = f(X_green,t-1 - X_brown,t-1)`
- `beta_C,brown,t = beta_C,brown,t-1 - shift_t`
- `beta_C,green,t = beta_C,green,t-1 + shift_t`

Core play: transition speed.

Increase endogenous transition speed from zero.
Rerun the model with the new transition speed.
Compare GDP against the fitted no-transition baseline from Step 2.
```{r step3_play_core_transition_speed}
transition_speed_play <- 0.001  # TODO [core:step3_speed] Change endogenous transition speed and compare GDP/energy-share paths Hint: Try 0.001 then 0.004
step3_play <- simulate_sim_iot_endogenous(calib3, T = 20, transition_speed = transition_speed_play)
```

Plot Step 3 core comparison.

Plot GDP paths for baseline and transition-speed play.
This isolates the macro effect of endogenous transition.
Use this as the main Step 3 comparison graphic.
```{r step3_plot_core, fig.height=4, fig.width=7}
plot(step2_baseline$year, step2_baseline$GDP, type = "l", lwd = 2, col = "steelblue",
     xlab = "year", ylab = "GDP", main = "Step 3 Core Play: transition speed")
lines(step3_play$year, step3_play$GDP, lwd = 2, col = "firebrick")
legend("topleft", legend = c("baseline (no transition)", paste0("play: ", transition_speed_play)),
       col = c("steelblue", "firebrick"), lty = 1, bty = "n")
```

Optional play: transition asymmetry / signal sensitivity.

Change how strongly the transition rule reacts to sector-output signals.
Rerun with the same transition speed but different signal weight.
Inspect brown/green demand-share paths to see structural reallocation sensitivity.
```{r step3_play_optional_signal}
transition_signal_weight_play <- 0.5  # TODO [optional:step3_signal] Change transition signal sensitivity and compare brown/green share dynamics Hint: Try 0.5, 1.0, 1.8
step3_opt <- simulate_sim_iot_endogenous(calib3, T = 20, transition_speed = transition_speed_play, transition_signal_weight = transition_signal_weight_play)

plot(step3_play$year, step3_play$betaC_brown, type = "l", lwd = 2, col = "firebrick",
     xlab = "year", ylab = "beta_C shares", main = "Step 3 Optional: signal sensitivity")
lines(step3_opt$year, step3_opt$betaC_brown, lwd = 2, col = "firebrick", lty = 2)
lines(step3_play$year, step3_play$betaC_green, lwd = 2, col = "darkgreen")
lines(step3_opt$year, step3_opt$betaC_green, lwd = 2, col = "darkgreen", lty = 2)
legend("right", legend = c("brown base", "brown play", "green base", "green play"),
       col = c("firebrick", "firebrick", "darkgreen", "darkgreen"), lty = c(1, 2, 1, 2), bty = "n")
```

### Interpretation

Step 3 turns transition into a macro-behavioral outcome, starting from the fitted Step 2 baseline.
## Step 4: RoW-lite

### Objective

Add exports, import leakage, and trade balance tracking.

### Equations

- `FD_dom,i,t = C_i,t + G_i,t + I_i + EX_i,t`
- `IM_i,t = m_i * FD_dom,i,t`
- `FD_net,i,t = FD_dom,i,t - IM_i,t`
- `TB_t = EX_t - IM_t`

Define RoW-lite simulation helpers.

This block extends the model with a minimal external sector (RoW-lite).
Pseudo-code: keep exports exogenous, compute imports as leakage from domestic final demand.
Use net demand (FD_dom - IM) for production, then update GDP/taxes/wealth/debt/trade each period.
Track TB = EX - IM while preserving the endogenous transition channel from Step 3.
This gives an interpretable open-economy extension without full MRIO structure.
```{r step4_functions_row_lite}
calibrate_sim_iot_row <- function(iot, wealth_init, tau_y = NULL) {
  tau_guess <- if (is.null(tau_y)) min(max(iot$G0 / pmax(iot$Y0, 1), 0.1), 0.5) else tau_y
  list(
    base_year = iot$base_year,
    n = iot$n,
    sector_codes = iot$sector_codes,
    sector_labels = iot$sector_labels,
    L = iot$L0,
    va_coeff = iot$va_coeff,
    beta_C = iot$beta_C,
    beta_G = iot$beta_G,
    I_i0 = iot$I_i0,
    EX_i0 = iot$EX_i0,
    m_i = iot$m_i,
    G0 = iot$G0,
    tau_y = tau_guess,
    V0 = wealth_init$V0,
    B0 = wealth_init$B0,
    idx = find_energy_indices(iot$sector_codes)
  )
}

simulate_sim_iot_row_lite <- function(calib,
                                      T = 20,
                                      c_y = 0.82,
                                      c_v = 0.03,
                                      g_G = 0.01,
                                      ex_growth = 0,
                                      import_leakage_scale = 1,
                                      transition_speed = 0.0015) {
  years <- calib$base_year + seq_len(T) - 1
  out <- data.frame(
    year = years,
    GDP = NA_real_, TAX = NA_real_, YD = NA_real_, C = NA_real_, G = NA_real_,
    V = NA_real_, DEF = NA_real_, B = NA_real_, EX = NA_real_, IM = NA_real_, TB = NA_real_,
    betaC_brown = NA_real_, betaC_green = NA_real_
  )

  V_prev <- calib$V0
  B_prev <- calib$B0
  G_prev <- calib$G0
  x_prev <- as.numeric(calib$L %*% (calib$beta_C * sum(calib$I_i0) + calib$beta_G * calib$G0 + calib$I_i0 + calib$EX_i0))
  beta_C <- calib$beta_C
  beta_G <- calib$beta_G

  for (tt in seq_len(T)) {
    G_t <- if (tt == 1) calib$G0 else G_prev * (1 + g_G)
    EX_i_t <- calib$EX_i0 * (1 + ex_growth)^(tt - 1)

    if (is.finite(calib$idx$idx_green) && is.finite(calib$idx$idx_brown)) {
      signal <- (x_prev[calib$idx$idx_green] - x_prev[calib$idx$idx_brown]) / pmax(sum(abs(x_prev)), 1)
      shift <- max(0, transition_speed * (1 + signal))
      shift <- min(shift, max(beta_C[calib$idx$idx_brown] - 1e-8, 0))
      beta_C[calib$idx$idx_brown] <- beta_C[calib$idx$idx_brown] - shift
      beta_C[calib$idx$idx_green] <- beta_C[calib$idx$idx_green] + shift
    }

    m_eff <- pmin(pmax(calib$m_i * import_leakage_scale, 0), 0.99)
    S <- 1 - m_eff

    k <- as.numeric(t(calib$va_coeff) %*% (calib$L %*% (S * beta_C)))
    b <- as.numeric(t(calib$va_coeff) %*% (calib$L %*% (S * (beta_G * G_t + calib$I_i0 + EX_i_t))))
    den <- 1 - c_y * (1 - calib$tau_y) * k
    C_t <- max((c_y * (1 - calib$tau_y) * b + c_v * V_prev) / den, 0)

    fd_dom_t <- beta_C * C_t + beta_G * G_t + calib$I_i0 + EX_i_t
    im_i_t <- m_eff * fd_dom_t
    fd_net_t <- pmax(fd_dom_t - im_i_t, 0)

    x_t <- pmax(as.numeric(calib$L %*% fd_net_t), 0)
    Y_t <- sum(calib$va_coeff * x_t)
    TAX_t <- calib$tau_y * Y_t
    YD_t <- Y_t - TAX_t

    V_t <- V_prev + YD_t - C_t
    DEF_t <- G_t - TAX_t
    B_t <- B_prev + DEF_t

    EX_t <- sum(EX_i_t)
    IM_t <- sum(im_i_t)
    TB_t <- EX_t - IM_t

    out[tt, c("GDP", "TAX", "YD", "C", "G", "V", "DEF", "B", "EX", "IM", "TB", "betaC_brown", "betaC_green")] <- c(
      Y_t, TAX_t, YD_t, C_t, G_t, V_t, DEF_t, B_t, EX_t, IM_t, TB_t,
      if (is.finite(calib$idx$idx_brown)) beta_C[calib$idx$idx_brown] else NA_real_,
      if (is.finite(calib$idx$idx_green)) beta_C[calib$idx$idx_green] else NA_real_
    )

    x_prev <- x_t
    V_prev <- V_t
    B_prev <- B_t
    G_prev <- G_t
  }

  out
}
```

Build RoW-lite calibration and baseline path.

Reuse Step 2 calibration (no reload/reparse here).
Run the RoW-lite baseline with zero transition speed.
This provides the trade-balance reference with minimal extra runtime.
```{r step4_run_baseline}
if (!exists("calib4", inherits = FALSE)) {
  core_config <- make_core_config()
  core_iot <- download_or_load_iot(core_config)
  core_wealth <- load_wealth_init(core_config)
  calib4 <- calibrate_sim_iot_row(core_iot, core_wealth)
}
step4_baseline <- simulate_sim_iot_row_lite(calib4, T = 20, transition_speed = 0)
```

Core play: import leakage.

Scale import leakage up or down.
Rerun the RoW-lite model with the new leakage factor.
Assess GDP and trade-balance sensitivity.
```{r step4_play_core_imports}
import_leakage_scale_play <- 0.8  # TODO [core:step4_imports] Change import leakage and inspect GDP/trade balance Hint: Above 1 increases leakage, below 1 reduces leakage
step4_core_play <- simulate_sim_iot_row_lite(calib4, T = 20, import_leakage_scale = import_leakage_scale_play)
```

Plot Step 3 core comparison.

Plot trade balance for baseline vs import-leakage play.
This shows how import dependence shifts TB.
Use this as the main Step 4 diagnostic.
```{r step4_plot_core, fig.height=4, fig.width=7}
plot(step4_baseline$year, step4_baseline$TB, type = "l", lwd = 2, col = "steelblue",
     xlab = "year", ylab = "TB = EX - IM", main = "Step 4 Core Play: trade balance")
lines(step4_core_play$year, step4_core_play$TB, lwd = 2, col = "firebrick")
legend("topleft", legend = c("baseline", paste0("play: ", import_leakage_scale_play)),
       col = c("steelblue", "firebrick"), lty = 1, bty = "n")
```

Optional play: export growth.

Change export growth and rerun RoW-lite.
Plot GDP to visualize export-led effects.
Keep all other parameters unchanged.
```{r step4_play_optional_exports}
ex_growth_play <- 0.03  # TODO [optional:step4_exports] Change export growth and inspect GDP response Hint: Positive export growth raises final demand
step4_opt <- simulate_sim_iot_row_lite(calib4, T = 20, ex_growth = ex_growth_play)

ggplot2::ggplot(step4_opt, ggplot2::aes(year, GDP)) +
  ggplot2::geom_line(linewidth = 1, color = "purple4") +
  ggplot2::labs(title = "Step 4 Optional: GDP with export growth", y = "GDP") +
  ggplot2::theme_minimal()
```

### MRIO caveat (equations/text only)

Imports in this step use domestic leakage rates. In MRIO, imported bundles should be mapped to foreign technologies and foreign emission intensities.

## Step 5: IOT Load + Exogenous Transition (Advanced/Optional)

### Objective

Use the same loaded IOT structure to run an exogenous 20-year energy transition under alternative closure assumptions.

### Equations

- `x_t = (I - A_t)^(-1) f_t`
- Closure determines how non-target sectors absorb adjustment
- Exogenous transition targets enter as `eps_green` and `eps_brown`

Define Step 5 exogenous-transition function.

This function is introduced only in Step 5 (advanced/optional).
Pseudo-code: each year call the closure solver, enforce exogenous brown/green rates, and store GDP plus energy-sector outputs.

```{r step5_functions_exogenous_transition}
source("closure_utils.R")
simulate_iot_exogenous_transition <- function(iot,
                                              T = 20,
                                              closure_option = "residual-others",
                                              g_target = 0.01,
                                              eps_green = 0.04,
                                              eps_brown = -0.04,
                                              max_iter = 20) {
  idx <- find_energy_indices(iot$sector_codes)

  x_prev <- as.numeric(iot$x0)
  F_prev <- as.numeric(iot$F0)
  years <- iot$base_year + seq_len(T) - 1

  out <- data.frame(
    year = years,
    closure = closure_option,
    GDP = NA_real_,
    X_green = NA_real_,
    X_brown = NA_real_,
    g_green = NA_real_,
    g_brown = NA_real_,
    g_other = NA_real_,
    io_resid = NA_real_
  )

  for (tt in seq_len(T)) {
    sol <- solve_io_consistency(
      Z_base = iot$Z0,
      F_prev = F_prev,
      x_init = x_prev,
      diag_mat = diag(iot$n),
      option = closure_option,
      eps_R = eps_green,
      eps_N = eps_brown,
      g = g_target,
      idx_ren = idx$idx_green,
      idx_nren = idx$idx_brown,
      p_out_ren = 1,
      p_out_nren = 1,
      va_coeff = iot$va_coeff,
      target = "output",
      max_iter = max_iter,
      rel_io_tol = 1e-8
    )

    x_now <- pmax(as.numeric(sol$X), 0)
    F_now <- pmax(as.numeric(sol$F), 0)

    out[tt, c("GDP", "X_green", "X_brown", "g_green", "g_brown", "g_other", "io_resid")] <- c(
      sum(iot$va_coeff * x_now),
      x_now[idx$idx_green],
      x_now[idx$idx_brown],
      sol$g_R,
      sol$g_N,
      sol$g_O,
      sol$rel_io_resid
    )

    x_prev <- x_now
    F_prev <- F_now
  }

  out
}
```
```{r step5_run_load_iot}
step5_T <- if (interactive()) 12 else 20
step5_max_iter <- if (interactive()) 12 else 20

if (!exists("core_iot", inherits = FALSE)) {
  core_config <- make_core_config()
  core_iot <- download_or_load_iot(core_config)
}
iot <- core_iot
c(country = iot$country, year = iot$base_year, n_sectors = iot$n)
```

Run baseline closure path.

Run the exogenous transition with the baseline closure.
Keep aggregate growth fixed and target green/brown changes.
Store the resulting GDP and sector paths.
```{r step5_run_baseline}
step5_baseline <- simulate_iot_exogenous_transition(
  iot,
  T = step5_T,
  closure_option = "residual-others",
  g_target = 0.01,
  eps_green = 0.04,
  eps_brown = -0.04,
  max_iter = step5_max_iter
)
```

Core play: switch closure option.

Switch to a different closure rule for the same targets.
Rerun the transition with that closure option.
This isolates how closure choice changes outcomes.
```{r step5_play_core_closure}
closure_options <- c("residual-others", "fixed-others", "uniform-demand", "eps-only")
closure_play <- closure_options[3]  # TODO [core:step5_closure] Switch closure option and inspect GDP and green/brown paths Hint: Compare fixed-others vs uniform-demand

step5_closure_play <- simulate_iot_exogenous_transition(
  iot,
  T = step5_T,
  closure_option = closure_play,
  g_target = 0.01,
  eps_green = 0.04,
  eps_brown = -0.04,
  max_iter = step5_max_iter
)
```

Plot closure comparison.

Plot GDP for baseline vs closure-play runs.
Use the same axes to see differences in adjustment paths.
The gap highlights closure sensitivity.
```{r step5_plot_core, fig.height=4, fig.width=7}
plot(step5_baseline$year, step5_baseline$GDP, type = "l", lwd = 2, col = "steelblue",
     xlab = "year", ylab = "GDP", main = "Step 5 Core Play: closure effect on GDP")
lines(step5_closure_play$year, step5_closure_play$GDP, lwd = 2, col = "firebrick")
legend("topleft", legend = c("baseline", paste0("play: ", closure_play)),
       col = c("steelblue", "firebrick"), lty = 1, bty = "n")
```

Optional play: strengthen exogenous transition rates.

Change the exogenous green/brown growth targets.
Rerun the transition and compute the brown/green ratio.
Plot the ratio to visualize structural shift speed.
```{r step5_play_optional_eps}
eps_green_play <- 0.02  # TODO [optional:step5_eps] Change exogenous green growth target and compare brown/green ratio Hint: Use eps_brown = -eps_green
eps_brown_play <- -eps_green_play

step5_eps_play <- simulate_iot_exogenous_transition(
  iot,
  T = step5_T,
  closure_option = "residual-others",
  g_target = 0.01,
  eps_green = eps_green_play,
  eps_brown = eps_brown_play,
  max_iter = step5_max_iter
)

ggplot2::ggplot(step5_eps_play, ggplot2::aes(year, X_brown / pmax(X_green, 1e-9))) +
  ggplot2::geom_line(linewidth = 1, color = "firebrick") +
  ggplot2::labs(title = "Step 5 Optional: brown/green output ratio", y = "X_brown / X_green") +
  ggplot2::theme_minimal()
```

### Interpretation

Closure choice and exogenous energy targets change the sectoral adjustment path even when aggregate growth is fixed.

## Step 6: AEA Production Emissions

### Objective

Attach direct production CO2 coefficients and compare baseline vs transition emissions paths.

### Equations

- `CO2_t = sum_i(s_i * x_i,t)`
- `s_i`: direct sector intensity (`kg CO2 / M EUR`)

Declare emissions configuration (first appearance in tutorial).

Declare emissions configuration (country, year, table type).
This config is separate from Steps 1–4.
It is used only for emissions attachment.
```{r step6_run_emissions_config}
make_emissions_config <- function() {
  list(
    country = Sys.getenv("SFC_EMIS_COUNTRY", "BE"),
    year = Sys.getenv("SFC_EMIS_YEAR", "2020"),
    scope = Sys.getenv("SFC_EMIS_SCOPE", "TOTAL"),
    table_type = Sys.getenv("SFC_EMIS_TABLE_TYPE", "industry_by_industry"),
    freq = "A",
    iot_unit = "MIO_EUR",
    wealth_unit = "MIO_EUR",
    wealth_co_nco = "NCO",
    wealth_na_item = "BF90",
    wealth_finpos = "LIAB",
    emissions_airpol = Sys.getenv("SFC_EMIS_AIRPOL", "CO2"),
    emissions_unit = "THS_T",
    cache_dir = "data",
    enforce_co2_consistency = TRUE
  )
}
emissions_config <- make_emissions_config()
```

Define emissions loaders and attachment functions.

This block maps sector output paths to direct production CO2 emissions.
Pseudo-code: normalize sector codes and align IO sectors with available AEA emissions accounts.
Compute intensity (kg per MEUR) from AEA emissions and base-year output.
Run model with stored sector output X_t and compute CO2_t as dot(X_t, intensity).
This yields production-based baseline vs transition emissions trajectories.
```{r step6_functions_emissions}
normalize_nace_code <- function(x) {
  y <- toupper(as.character(x))
  y <- gsub("-", "_", y)
  y <- gsub("\\.", "", y)
  y <- gsub("^([A-Z])(\\d{2})_(\\d{2})$", "\\1\\2_\\1\\3", y, perl = TRUE)
  y
}

get_aea_codes <- function(cfg) {
  params <- list(freq = cfg$freq, airpol = cfg$emissions_airpol, unit = cfg$emissions_unit, geo = cfg$country, time = as.character(cfg$year))
  js <- fetch_eurostat_json("env_ac_ainah_r2", params, cache_dir = cfg$cache_dir)
  vals <- extract_values_by_dim(js, "nace_r2")
  unique(normalize_nace_code(names(vals)[is.finite(vals) & !is.na(vals)]))
}

align_iot_to_aea <- function(iot, cfg) {
  aea_norm <- get_aea_codes(cfg)
  sec_norm <- normalize_nace_code(iot$sector_codes)
  keep <- sec_norm %in% aea_norm
  idx <- which(keep)

  iot$sector_codes <- iot$sector_codes[idx]
  iot$sector_labels <- iot$sector_labels[idx]
  iot$n <- length(idx)
  iot$Z0 <- iot$Z0[idx, idx, drop = FALSE]
  iot$A0 <- iot$A0[idx, idx, drop = FALSE]
  iot$L0 <- solve(diag(iot$n) - iot$A0 + diag(1e-8, iot$n))

  for (nm in c("x0", "C_i0", "G_i0", "I_i0", "EX_i0", "m_i", "va_coeff", "beta_C", "beta_G")) iot[[nm]] <- iot[[nm]][idx]

  iot$F0 <- iot$C_i0 + iot$G_i0 + iot$I_i0 + iot$EX_i0
  iot$G0 <- sum(iot$G_i0)
  iot$Y0 <- sum(iot$va_coeff * iot$x0)
  if (sum(iot$beta_C) > 0) iot$beta_C <- iot$beta_C / sum(iot$beta_C)
  if (sum(iot$beta_G) > 0) iot$beta_G <- iot$beta_G / sum(iot$beta_G)
  iot
}

load_aea_emissions <- function(cfg, sector_codes, x0) {
  if (!identical(cfg$table_type, "industry_by_industry")) {
    stop("AEA emissions are not directly available for product_by_product mode.", call. = FALSE)
  }

  params <- list(freq = cfg$freq, airpol = cfg$emissions_airpol, unit = cfg$emissions_unit, geo = cfg$country, time = as.character(cfg$year))
  js <- fetch_eurostat_json("env_ac_ainah_r2", params, cache_dir = cfg$cache_dir)
  vals <- extract_values_by_dim(js, "nace_r2")
  names(vals) <- normalize_nace_code(names(vals))

  sec_norm <- normalize_nace_code(sector_codes)
  em_ths_t <- as.numeric(vals[sec_norm])
  names(em_ths_t) <- sector_codes

  missing <- !is.finite(em_ths_t)
  if (any(missing)) stop("CO2 missing for sectors: ", paste(sector_codes[missing], collapse = ", "), call. = FALSE)

  intensity <- (em_ths_t * 1e6) / pmax(as.numeric(x0), 1e-9)
  intensity[!is.finite(intensity)] <- 0
  data.frame(sector = sector_codes, intensity_kg_per_meur = intensity, stringsAsFactors = FALSE)
}

attach_production_emissions <- function(sim_result, intensity_tbl, sector_codes) {
  idx <- match(sector_codes, intensity_tbl$sector)
  s <- intensity_tbl$intensity_kg_per_meur[idx]
  s[!is.finite(s)] <- 0
  co2_kg <- as.numeric(sim_result$x %*% s)
  out <- sim_result$aggregate
  out$CO2_Mt <- co2_kg / 1e9
  out
}

simulate_row_with_x <- function(calib,
                                T = 20,
                                c_y = 0.82,
                                c_v = 0.03,
                                g_G = 0.01,
                                ex_growth = 0,
                                import_leakage_scale = 1,
                                transition_speed = 0.0015) {
  years <- calib$base_year + seq_len(T) - 1
  agg <- data.frame(
    year = years,
    GDP = NA_real_, TAX = NA_real_, YD = NA_real_, C = NA_real_, G = NA_real_,
    V = NA_real_, DEF = NA_real_, B = NA_real_, EX = NA_real_, IM = NA_real_, TB = NA_real_,
    betaC_brown = NA_real_, betaC_green = NA_real_
  )
  x_store <- matrix(NA_real_, nrow = T, ncol = calib$n)

  V_prev <- calib$V0
  B_prev <- calib$B0
  G_prev <- calib$G0
  x_prev <- as.numeric(calib$L %*% (calib$beta_C * sum(calib$I_i0) + calib$beta_G * calib$G0 + calib$I_i0 + calib$EX_i0))
  beta_C <- calib$beta_C
  beta_G <- calib$beta_G

  for (tt in seq_len(T)) {
    G_t <- if (tt == 1) calib$G0 else G_prev * (1 + g_G)
    EX_i_t <- calib$EX_i0 * (1 + ex_growth)^(tt - 1)

    if (is.finite(calib$idx$idx_green) && is.finite(calib$idx$idx_brown)) {
      signal <- (x_prev[calib$idx$idx_green] - x_prev[calib$idx$idx_brown]) / pmax(sum(abs(x_prev)), 1)
      shift <- max(0, transition_speed * (1 + signal))
      shift <- min(shift, max(beta_C[calib$idx$idx_brown] - 1e-8, 0))
      beta_C[calib$idx$idx_brown] <- beta_C[calib$idx$idx_brown] - shift
      beta_C[calib$idx$idx_green] <- beta_C[calib$idx$idx_green] + shift
    }

    m_eff <- pmin(pmax(calib$m_i * import_leakage_scale, 0), 0.99)
    S <- 1 - m_eff

    k <- as.numeric(t(calib$va_coeff) %*% (calib$L %*% (S * beta_C)))
    b <- as.numeric(t(calib$va_coeff) %*% (calib$L %*% (S * (beta_G * G_t + calib$I_i0 + EX_i_t))))
    den <- 1 - c_y * (1 - calib$tau_y) * k
    C_t <- max((c_y * (1 - calib$tau_y) * b + c_v * V_prev) / den, 0)

    fd_dom_t <- beta_C * C_t + beta_G * G_t + calib$I_i0 + EX_i_t
    im_i_t <- m_eff * fd_dom_t
    fd_net_t <- pmax(fd_dom_t - im_i_t, 0)

    x_t <- pmax(as.numeric(calib$L %*% fd_net_t), 0)
    Y_t <- sum(calib$va_coeff * x_t)
    TAX_t <- calib$tau_y * Y_t
    YD_t <- Y_t - TAX_t

    V_t <- V_prev + YD_t - C_t
    DEF_t <- G_t - TAX_t
    B_t <- B_prev + DEF_t

    EX_t <- sum(EX_i_t)
    IM_t <- sum(im_i_t)
    TB_t <- EX_t - IM_t

    agg[tt, c("GDP", "TAX", "YD", "C", "G", "V", "DEF", "B", "EX", "IM", "TB", "betaC_brown", "betaC_green")] <- c(
      Y_t, TAX_t, YD_t, C_t, G_t, V_t, DEF_t, B_t, EX_t, IM_t, TB_t,
      if (is.finite(calib$idx$idx_brown)) beta_C[calib$idx$idx_brown] else NA_real_,
      if (is.finite(calib$idx$idx_green)) beta_C[calib$idx$idx_green] else NA_real_
    )

    x_store[tt, ] <- x_t
    x_prev <- x_t
    V_prev <- V_t
    B_prev <- B_t
    G_prev <- G_t
  }

  list(aggregate = agg, x = x_store)
}
```

Prepare Step 6 calibration and baseline/transition runs.

Load IO and wealth data for the emissions configuration.
Optionally align IO sectors to AEA availability.
Build calibration and load emission intensities.
```{r step6_run_calibrate}
iot_emis <- download_or_load_iot(emissions_config)
if (isTRUE(emissions_config$enforce_co2_consistency)) iot_emis <- align_iot_to_aea(iot_emis, emissions_config)
wealth_emis <- load_wealth_init(emissions_config)
calib5 <- calibrate_sim_iot_row(iot_emis, wealth_emis)
aea_intensity <- load_aea_emissions(emissions_config, iot_emis$sector_codes, iot_emis$x0)
```

Core play: compare baseline and transition CO2.

Run baseline and transition simulations with stored sector output.
Attach production CO2 intensities to each path.
Combine scenarios into a single comparison table.
```{r step6_play_core_transition}
transition_speed_emis_play <- 0.0  # TODO [core:step6_transition] Compare baseline and transition CO2 paths Hint: Use 0 for baseline and positive speed for transition

step6_baseline_sim <- simulate_row_with_x(calib5, T = 20, transition_speed = 0)
step6_transition_sim <- simulate_row_with_x(calib5, T = 20, transition_speed = transition_speed_emis_play)

step6_base <- attach_production_emissions(step6_baseline_sim, aea_intensity, iot_emis$sector_codes)
step6_trans <- attach_production_emissions(step6_transition_sim, aea_intensity, iot_emis$sector_codes)

step6_compare <- rbind(
  data.frame(step6_base, scenario = "baseline"),
  data.frame(step6_trans, scenario = paste0("transition:", transition_speed_emis_play))
)
```

Plot Step 6 core comparison.

Plot production CO2 for baseline vs transition.
Use the same axes to highlight differences.
This is the main emissions comparison plot.
```{r step6_plot_core, fig.height=4, fig.width=7}
ggplot2::ggplot(step6_compare, ggplot2::aes(year, CO2_Mt, color = scenario)) +
  ggplot2::geom_line(linewidth = 1) +
  ggplot2::labs(title = "Step 6 Core Play: direct production CO2", y = "Mt CO2") +
  ggplot2::theme_minimal()
```

Optional play: sensitivity to intensity decline.

Apply an exogenous decline to emission intensities.
Recompute CO2 with the adjusted intensities.
Plot the decarbonized path for sensitivity.
```{r step6_play_optional_intensity_decline}
intensity_decline_play <- 0.0  # TODO [optional:step6_intensity] Apply annual intensity decline and compare CO2 path Hint: This is exogenous decarbonization of direct intensity

aea_intensity_play <- aea_intensity
aea_intensity_play$intensity_kg_per_meur <- aea_intensity_play$intensity_kg_per_meur * (1 - intensity_decline_play)

step6_play <- attach_production_emissions(step6_transition_sim, aea_intensity_play, iot_emis$sector_codes)

ggplot2::ggplot(step6_play, ggplot2::aes(year, CO2_Mt)) +
  ggplot2::geom_line(linewidth = 1, color = "darkred") +
  ggplot2::labs(title = "Step 6 Optional: with intensity decline", y = "Mt CO2") +
  ggplot2::theme_minimal()
```

### Consumption-emissions caveat (equations/text only)

A consumption footprint would require domestic and imported embodied intensities, not only domestic production intensities.

## Final Snapshot

Report final-year key aggregates from Step 6.

Extract the final year from the emissions comparison.
Select the key aggregate variables for reporting.
This produces the compact end-of-tutorial table.
```{r final_snapshot}
last_year <- max(step6_compare$year)
summary_final <- step6_compare[step6_compare$year == last_year, c("scenario", "GDP", "V", "B", "TB", "CO2_Mt")]
summary_final <- summary_final[order(summary_final$scenario), ]
rownames(summary_final) <- NULL
summary_final
```

## Limitations

- Prices are fixed.
- No banking, portfolio, or inventories.
- RoW-lite is pedagogical; MRIO is required for full footprint attribution.
